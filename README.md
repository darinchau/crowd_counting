## Introduction

This research project on crowd counting follows the work of Parasite-Host Network by JiaJie Li et. al. https://jiajie.media/portfolio/phnet/. The work is conducted under the supervision of Prof. Chan Sheung-Han Gary and his research fellow Sizhe Song, and approved by the UROP office in HKUST.

This README shall contain some instructions for training, as well as the documentation of the code and the explaination of the overall folder structure.

## Training instructions
#### Step 1: Preprocessing
If you want to run the venice [Venice dataset](https://drive.google.com/file/d/15PUf7C3majy-BbWJSSHaXUlot0SUh3mJ/view "Venice dataset") or the Unity dataset (link to be provided) generated by the author, we have written the code for preprocessing already. 

The github repo should also have the preprocessed data and density maps (tracked by git-lfs I dont know if it works nicely when you clone the repo)


If you want to preprocess venice dataset, at the entrypoint of `preprocess.py`, put
`venice(SOURCE_PATH="path to venice file", EXPORT_PATH="./datas/file name")`
and then run `python preprocess.py`

Similarly, if you run the unity dataset, put 
`unity(SOURCE_PATH="./unity/Set 1", EXPORT_PATH="./datas/Unity Batch 1")`
and run the code, where of course you modify the source path and export path accordingly.

##### Processing your own dataset
If you want to preprocess your own dataset, that would be fine too! You will need 4 things:
- The images, of course
- The frame index of the images. They specify the order of the images, and they should be in non-negative consecutive integers
- The ROI (region of interest) for each image. It is a Numpy array with shape `(image height, image width)` of 0s and 1s. This will serve as a mask for your image, where you can mask out the regions where humans would not appear
- A list of coordinates (provided as a Numpy array with shape `(Number of people, 2)`)

Now you would define a function that loads these things above into 3 separate dictionaries. The keys of these dictionaries would be the image name (e.g. "Frame 1", "Frame 2") and the values would be a tuple `(frame index, image/roi/density map)`. You can follow the psuedocode below for reference

    def load_my_dataset(SOURCE_PATH : str, EXPORT_PATH : str):
    	images, rois, dmaps = {}, {}, {}
    	# Loop through every data
    	for frame_idx in number_of_frames:
    		# Load the data
    		img = load image with frame_idx in RGB
    		roi = load roi corresponding to img
    		coords = load coordinates of humans corresponding to img
    		
    		# This function below is provided. This turns coordinates into density maps.
    		dmap = coords_to_density_map(coords, sigma=5)
    		
    		# Now make the entries in the dictionaries
    		images[img name] = (frame_idx, img)
    		rois[img name] = (frame_idx, roi)
    		dmaps[img name] = (frame_idx, dmaps)
    		
    	# This function below is also provided.  This makes the data from the dictionary
    	make_data(img, roi, dmap, EXPORT_PATH)

#### Step 2: Specifying the training and test data
If you clone the repo, you should find two text files, `train.txt` and `test.txt`. In these text files, enter the folder name that contains the data in the "datas" folder. For example if you have folder "venice", "unity batch 1" containing the venice dataset, and you want to use it for training, put

    venice
    unity batch 1

in your `train.txt`.

#### Step 3: Training
Just run `python main.py` and you are good to go. Perhaps we should explain some flags that you can also specify when the code runs

##### - -pre
Type: string | None, default: None
If you have a previous checkpoint you would like to load, put it's path here. This path will be prepended by the root_dir variable. See below

##### - -user_dir
Type: string, default: "./"
The root directory of the data. Defaults to the same directory as the `main.py` file. This might be useful if you are running your code on a gpu server and you have to put your data somewhere else.

##### - -batch_size
Type: int, default: 2
Batch size of training

##### - -progress_bar
Type: bool, default: false
Whether to use the progress bar during training or not. We recommend not if you are running on a server

##### - -debug
Type: bool, default: false
If set to true, instead of training in the training loop, the code will plot the training images and the density maps. Useful for, well, debugging.


## Documentation
We would probably not add these unless it is heavily requested. Meanwhile please look at the comments in the code - I hope they are sufficient. If you need help, feel free to raise an issue on GitHub.